{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bibliotecas e conexão com drive"
      ],
      "metadata": {
        "id": "UXcMiVA2bGn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "ttVJjTKVNygP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNkybA-0y-6n",
        "outputId": "1cedf0f9-39b9-44d2-a9c5-ab6cca777724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNPTLzq21Myf",
        "outputId": "4b1e639d-1bee-425c-924e-e3649dfb79a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   User ID        Username                                              Tweet  \\\n",
            "0   132131           flong  Station activity person against natural majori...   \n",
            "1   289683  hinesstephanie  Authority research natural life material staff...   \n",
            "2   779715      roberttran  Manage whose quickly especially foot none to g...   \n",
            "3   696168          pmason  Just cover eight opportunity strong policy which.   \n",
            "4   704441          noah87                      Animal sign six data good or.   \n",
            "\n",
            "   Retweet Count  Mention Count  Follower Count  Verified  Bot Label  \\\n",
            "0             85              1            2353     False          1   \n",
            "1             55              5            9617      True          0   \n",
            "2              6              2            4363      True          0   \n",
            "3             54              5            2242      True          1   \n",
            "4             26              3            8438     False          1   \n",
            "\n",
            "       Location           Created At            Hashtags  \n",
            "0     Adkinston  2020-05-11 15:29:50                 NaN  \n",
            "1    Sanderston  2022-11-26 05:18:10           both live  \n",
            "2  Harrisonfurt  2022-08-08 03:16:54         phone ahead  \n",
            "3  Martinezberg  2021-08-14 22:27:05  ever quickly new I  \n",
            "4  Camachoville  2020-04-13 21:24:21     foreign mention  \n"
          ]
        }
      ],
      "source": [
        "# Carregar o dataset\n",
        "dataset_path = '/content/drive/MyDrive/ponderadas8/Cópia de bot_detection_data.csv'\n",
        "\n",
        "# Carregar o dataset\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Inspecionar os dados\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Documentação + Código**\n",
        "\n",
        "# 1. Distribuição das Classes\n",
        "Antes de treinar o modelo, a distribuição das classes foi verificada para identificar possíveis desbalanceamentos entre bots e humanos:\n",
        "\n",
        "\n",
        "```\n",
        "print(df['Bot Label'].value_counts())\n",
        "\n",
        "```\n",
        "\n",
        "# 2. Tratamento de Colunas Não Numéricas\n",
        "As colunas categóricas foram convertidas para valores numéricos utilizando LabelEncoder para que o modelo pudesse processá-las. Isso foi necessário pois o algoritmo RandomForest não lida diretamente com variáveis categóricas.\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Tratar colunas categóricas\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "\n",
        "```\n",
        "# 3. Separação de Features e Labels\n",
        "O conjunto de dados foi dividido em X (features) e y (alvo). X contém todas as variáveis explicativas, enquanto y contém a variável alvo que classifica os bots e humanos.\n",
        "\n",
        "```\n",
        "X = df.drop(columns=['Bot Label'])\n",
        "y = df['Bot Label']\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# 4. Padronização dos Dados\n",
        "As features foram padronizadas utilizando StandardScaler para garantir que todas as variáveis tivessem a mesma escala.\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# 5. Balanceamento de Classes com SMOTE\n",
        "Como pode haver desbalanceamento entre bots e humanos, utilizei o SMOTE (Synthetic Minority Over-sampling Technique) para balancear as classes.\n",
        "\n",
        "```\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# 6. Divisão dos Dados em Treino e Teste\n",
        "O conjunto de dados foi dividido em 80% para treino e 20% para teste, com uma semente de aleatoriedade (random_state) para garantir a reprodutibilidade dos resultados.\n",
        "\n",
        "```\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# 7. Ajuste de Hiperparâmetros com GridSearchCV\n",
        "O GridSearchCV foi utilizado para encontrar os melhores hiperparâmetros para o modelo RandomForest. Por conta do tamanho do DF foi preciso acelerar o processo utilizando 50% dos dados de treino. Os hiperparâmetros otimizados incluíram o número de estimadores (n_estimators), a profundidade máxima das árvores (max_depth), e parâmetros de amostragem.\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],  # Reduzido o número de estimadores\n",
        "    'max_depth': [10],  # Fixado a profundidade\n",
        "    'min_samples_split': [2],  # Valor mínimo\n",
        "    'min_samples_leaf': [1],  # Valor mínimo\n",
        "    'bootstrap': [True]  # Mantendo o bootstrap como True\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Usar apenas 50% dos dados para ajuste de hiperparâmetros\n",
        "X_train_subsample, _, y_train_subsample, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_subsample, y_train_subsample)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# 8. Modelo Treinado\n",
        "O melhor modelo foi selecionado após o ajuste dos hiperparâmetros.\n",
        "\n",
        "```\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# 9. Avaliação do Modelo\n",
        "O desempenho do modelo foi avaliado utilizando acurácia e outras métricas como precisão, recall e F1-score. A acurácia foi obtida nos dados de teste:\n",
        "\n",
        "```\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "gyz1_izWYvIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts9de4UL0i17",
        "outputId": "38f4292e-63c7-4db2-9fa3-b2effac467fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot Label\n",
            "1    25018\n",
            "0    24982\n",
            "Name: count, dtype: int64\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [0, 1, 2, 3, 4]\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Acurácia: 0.49460431654676257\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.42      0.45      4931\n",
            "           1       0.50      0.57      0.53      5077\n",
            "\n",
            "    accuracy                           0.49     10008\n",
            "   macro avg       0.49      0.49      0.49     10008\n",
            "weighted avg       0.49      0.49      0.49     10008\n",
            "\n",
            "Melhores hiperparâmetros: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(df['Bot Label'].value_counts())\n",
        "\n",
        "\n",
        "print(df.select_dtypes(include=['object']).head())\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "X = df.drop(columns=['Bot Label'])\n",
        "y = df['Bot Label']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10],\n",
        "    'min_samples_split': [2],\n",
        "    'min_samples_leaf': [1],\n",
        "    'bootstrap': [True]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "X_train_subsample, _, y_train_subsample, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_subsample, y_train_subsample)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f'Melhores hiperparâmetros: {grid_search.best_params_}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}